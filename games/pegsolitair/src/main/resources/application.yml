logging:
  level.root: WARN
  level.ai.enpasos: DEBUG

muzero:
  activeGame: PEG_SOLITAIR
  run: train
  games:
    PEG_SOLITAIR:
      outputDir: ./memory/pegsolitair/
      values: [ -25,25 ]

      numSimulations: 100
      numParallelGamesPlayed: 1000

      # general
      modelName: MuZero-PegSolitair
      gameClassName: ai.enpasos.muzero.pegsolitair.config.PegSolitairGame
      actionClassName: ai.enpasos.muzero.pegsolitair.config.PegSolitairAction
      playerMode: SINGLE_PLAYER
      networkWithRewardHead: false
      inferenceDeviceType: GPU

      # game/environment
      size: 7
      maxMoves: 49  # size*size
      boardHeight: 7 # size
      boardWidth: 7 # size
      actionSpaceSize: 196  # size * size * 4 = point to start from and 4 directions

      # network sizing
      numObservationLayers: 1
      numActionLayers: 4   # one for each direction
      numChannels: 128     # 256 in the paper
      numResiduals: 16

      # network training
      # symmetryType: NONE
      # batchSize: 512
      symmetryType: SQUARE
      batchSize: 64

      numberOfTrainingStepsPerEpoch: 100

      numberOfTrainingSteps: 100000

      windowSize: 10000
      numUnrollSteps: 5
      tdSteps: 196 # here equals actionSpaceSize
      discount: 1.0
      # loss details
      weightDecay: 0.0001
      valueLossWeight: 1.0
      # network training - adam optimizer
      lrInit: 0.0001

      # play
      numberTrainingStepsOnStart: 0

      knownBoundsType: NONE





