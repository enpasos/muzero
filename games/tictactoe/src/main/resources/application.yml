logging:
  file.name: logs/muzero-tictactoe.log
  pattern:
    console: "%d %-5level %logger{0} : %msg%n"
    file: "%d %-5level [%thread] %logger : %msg%n"
  level:
    root: WARN
    ai.enpasos: DEBUG


muzero:
  activeGame: TICTACTOE
  run: train
  games:
    TICTACTOE:
      modelName: MuZero-TicTacToe
      gameClassName: ai.enpasos.muzero.tictactoe.config.TicTacToeGame
      actionClassName: ai.enpasos.muzero.tictactoe.config.TicTacToeAction
      playerMode: TWO_PLAYERS
      valueHeadType: EXPECTED # DISTRIBUTION
      networkWithRewardHead: false
      withRewardHead: false
      values: [ -1,0,1 ]
      numObservationLayers: 3
      numActionLayers: 1
      squeezeChannelRatio: 16  # on squeeze and excitation (SE) block
      numHiddenStateChannels: 5

      numberOfTrainingStepsPerEpoch: 40

      # windowValueSelfconsistencySize: 5000 <- postponed

      numUnrollSteps: 5
      tdSteps: 9 # size * size
      discount: 1.0
      weightDecay: 0.0001
      lrInit: 0.0001
      absorbingStateDropToZero: false # faster for integration test

      numberTrainingStepsOnStart: 0

      knownBoundsType: FROM_VALUES

      inferenceDeviceType: GPU
      outputDir: ./memory/tictactoe/
      numEpisodes: 1
      size: 3
      maxMoves: 9  # size*size
      boardHeight: 3 # size
      boardWidth: 3 # size
      actionSpaceSize: 9  # size*size

      # without symmetry usage
      # symmetryType: NONE
      # batchSize: 2048

      # using the square symmetry of the board
      symmetryType: SQUARE
      batchSize: 256

      numParallelGamesPlayed: 1000
      gameBufferWritingFormat: ZIPPED_PROTOCOL_BUFFERS # alternative: ZIPPED_JSON

      # Gumbel MuZero parameters
      initialGumbelM: 8
      cVisit: 10  # 50 in paper
      cScale: 1.0  # 1.0 in paper

      numSimulations: 30


      numResiduals: 8
      broadcastEveryN: 4
      numChannels: 256
      numBottleneckChannels: 128


      extraValueTrainingOn: false # false in paper

      temperatureRoot: 1.0  # obsolete .... 1.0 -> trust in logits as in paper; infinite -> random distributed = no trust in logits

      valueLossWeight: 1.0

      rootDirichletAlpha: 1.0
      rootExplorationFraction: 0.0

      windowSize: 25000
      #  maxGameLiveTime: 25000

      surpriseHandlingOn: false # false in paper
      surpriseCheckInterval: 10000

      numberOfTrainingSteps: 50000

      badActionProbabilityThreshold: 0.01
      variableStartFraction: 1.0
